# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_buffer_of_thought.ipynb.

# %% auto 0
__all__ = ['problem_distiller_prompt', 'instantiate_reasoning_prompt', 'core_task_summarization_prompt',
           'template_distiller_prompt', 'structure_prompt', 'distilled_task_extractor_prompt', 'LLM',
           'structure_template_text', 'distilled_task_extractor', 'template_store', 'user_id', 'long_term_memory',
           'namespace_for_memory', 'populate', 'meta_buffer', 'buffer_manager', 'memory', 'bot_graph', 'bot_agent',
           'ThoughtTemplate', 'BoTState', 'problem_distiller', 'template_retrieval', 'instantiate_reasoning',
           'template_distillation', 'dynamic_meta_buffer_update', 'update_required']

# %% ../nbs/03_buffer_of_thought.ipynb 5
from langgraph.graph import StateGraph, END, START, MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langgraph.store.base import BaseStore
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langgraph.store.memory import InMemoryStore
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
from typing import Literal, Optional
import textwrap
import os
from trustcall import create_extractor
from pathlib import Path
import uuid
from langchain.embeddings import init_embeddings
from .utils import *

# %% ../nbs/03_buffer_of_thought.ipynb 7
problem_distiller_prompt = textwrap.dedent(
    """
    ## Problem Distiller

    You are a highly professional and intelligent expert in information distillation. Your role is to extract essential information from user input queries to solve problems effectively. You also transform this extracted information into a suitable format based on the type of issue.

    ---

    ### Task Instructions

    1. **Key Information**:
    - Extract values and key variables from the user input.
    - Ensure all essential information required to solve the problem is provided.
    - Hand over this distilled information to the respective expert for task resolution.

    2. **Restrictions**:
    - Identify the objective of the problem.
    - Outline any corresponding constraints that must be adhered to.

    3. **Distilled Task**:
    - Extend the problem based on the extracted key information and constraints.
    - Summarize a meta problem that addresses the user query and accommodates more input and output variations.
    - Incorporate the real-world scenario of the extended problem.
    - Define types of key variables and information constraints from the original problem to restrict variables in the extended problem.
    - Use the input key information from the user query as an example to solve the problem.
    """
).strip()

# %% ../nbs/03_buffer_of_thought.ipynb 9
instantiate_reasoning_prompt = textwrap.dedent(
    """
    ## Meta Reasoner

    You are a Meta Reasoner who is extremely knowledgeable in various fields, including Computer Science, Math, Physics, Literature, History, Chemistry, Logical Reasoning, Culture, and Language. You are also skilled in applying high-level reasoning structures for different tasks. 

    ### Reasoning Structures:

    1. **Prompt-based Structure**:
    - **Best For**: Common Sense Reasoning, Application Scheduling.
    
    2. **Procedure-based Structure**:
    - **Best For**: Creative tasks like Creative Language Generation, and Text Comprehension.
    
    3. **Programming-based Structure**:
    - **Best For**: Mathematical Reasoning, Code Programming.
    - Can transform real-world problems into programming problems to solve efficiently.

    ---

    ### Reasoning Instantiation

    **Your Task:**

    1. **Contextual Analysis**: Deliberately consider the context and the problem distilled from the problem distiller. Use your understanding to identify a suitable domain expert for solving the problem.

    2. **Structure Selection**: Based on the distilled information, select one of the reasoning structures suitable for addressing the problem.

    3. **Template Application**: If a thought-template is provided, directly follow it to instantiate the solution for the given problem.
    """
).strip()

# %% ../nbs/03_buffer_of_thought.ipynb 11
# prompt to infer the core task summary. That one is needed for contextual search for relevant in-task and cross-task templates as few-shot examples for generating the
core_task_summarization_prompt = textwrap.dedent(
    """
    ## Prompt for Template Distillation:

    **User Input**:
    **Problem Description**: {distilled_task}
    **Solution Steps or Code**: {solution_steps}

    1. **Core task summarization**:
        Identify and describe the basic type and core challenges of the problem, such as classifying it as a mathematical problem (e.g., solving a quadratic equation), a data structure problem (e.g., array sorting), an algorithm problem (e.g., search algorithms), etc. And analyze the most efficient way to solve the problem.
    """
).strip()


template_distiller_prompt = textwrap.dedent(
    """
    ## Prompt for Template Distillation (continued)

    2. **Solution Steps Description**:
    Outline the general solution steps, including how to define the problem, determine variables, list key equations or constraints, choose appropriate solving strategies and methods, and how to verify the correctness of the results.

    3. **General Answer Template**:
    Based on the above analysis, propose a template or approach that can be widely applied to this type of problem, including possible variables, functions, class definitions, etc. If it is a programming problem, provide a set of base classes and interfaces that can be used to construct solutions to specific problems.

    Please ensure that your response is highly concise and structured, so that specific solutions can be transformed into generalizable methods.

    [Optional] Here are some exemplars of the thought-template:

    <in-task-examples>
    {in_task_examples}
    <in-task-examples>

    <cross-task-examples>
    {cross_task_examples}
    <cross-task-examples>
    """
).strip()

# %% ../nbs/03_buffer_of_thought.ipynb 13
structure_prompt = textwrap.dedent(
    """
    Extract the items of the 'ThoughtTemplate' Pydantic class from the previous conversation.
                                    
    <convo>
    {conversation}
    </convo> 
    """
).strip()

distilled_task_extractor_prompt = textwrap.dedent(
    """
    Extract the content of the 'Extended Problem' subsection within the 'Distilled Task' section from the entire distilled problem description.

    <distilled-problem>
    {distilled_problem}
    <distilled-problem>
    """
).strip()

# %% ../nbs/03_buffer_of_thought.ipynb 15
class ThoughtTemplate(BaseModel):
    """Defining the three fields of the Thought Template"""

    task_description: str = Field(description="Task Description")
    solution_description: str = Field(description="Solution Description")
    thought_template: str = Field(description="Thought Template")

# %% ../nbs/03_buffer_of_thought.ipynb 17
# Setup Large Language Model (LLM)
LLM = ChatOpenAI(
    model_name="gpt-4o-mini",
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.0,
)

# %% ../nbs/03_buffer_of_thought.ipynb 18
# Define Trustcall instance for sane extraction of the Thought Template items: Task Description, Solution Description, Thought Template
structure_template_text = create_extractor(
    LLM, tools=[ThoughtTemplate], tool_choice="ThoughtTemplate"
)

# Extract the distilled task from the distilled problem. Required for the semantic search in the Template retrieval step.
distilled_task_extractor = (
    PromptTemplate.from_template(
        template=distilled_task_extractor_prompt) | LLM
)

# %% ../nbs/03_buffer_of_thought.ipynb 21
# Create store with semantic search enabled
template_store = InMemoryStore(
    index={
        "embed": init_embeddings(model="openai:text-embedding-3-small"),
        "dims": 1536,
        "fields": ["task_description"],
    }
)

# %% ../nbs/03_buffer_of_thought.ipynb 23
user_id = "user_123"
long_term_memory = "thought_templates"
namespace_for_memory = (user_id, long_term_memory)

populate = True
# Optional, we populate the memory with some templates
if populate:
    # Dynamically determine the notebook's directory
    notebook_dir = Path(
        __file__).parent if "__file__" in globals() else Path.cwd()

    # Define the path relative to the notebook's directory
    template_path = notebook_dir / "data" / long_term_memory

    # Ensure the directory exists before iterating
    if populate and template_path.exists():
        for md_fl in template_path.iterdir():
            template_name, _ = md_fl.name.split(".")
            with open(md_fl) as fl:
                template_store.put(
                    namespace_for_memory, template_name, markdown_to_json(
                        fl.read())
                )
    else:
        print(f"Template path '{template_path}' does not exist.")

# %% ../nbs/03_buffer_of_thought.ipynb 25
class BoTState(MessagesState):
    # thought template possibly extracted from the long-term memory
    template_text: Optional[str]
    # part of the distilled problem description. Required for similarity computations
    distilled_task: str

# %% ../nbs/03_buffer_of_thought.ipynb 27
def problem_distiller(state: BoTState) -> dict:
    """
    Distills task information from the forwarded problem description using a Language Model (LLM).

    This function represents the problem distillation step in the Buffer of Thoughts (BoT) framework.
    It processes the most recent message, which is the original problem description, in the agent's
    state to extract a distilled representation of the task and updates the state with the distilled task.

    Parameters
    ----------
    state : BoTState
        The current state of the agent, which contains the message history and other relevant attributes.

    Returns
    -------
    dict
        A dictionary with the following keys:
        - "distilled_task" : str
            The distilled task description extracted from the latest message which is the problem description.
        - "messages" : str
            The distilled problem description which contains the distilled task description but also a key information and problem constraints.
    """
    # Invoke the LLM with the problem distiller prompt and the latest message
    distilled_task = LLM.invoke(
        [problem_distiller_prompt, state["messages"][-1]])

    # Extract the distilled task description from the LLM response
    return {
        "distilled_task": distilled_task_extractor.invoke(
            distilled_task.content
        ).content,
        "messages": distilled_task,  # Update state with the distilled task message
    }

# %% ../nbs/03_buffer_of_thought.ipynb 28
def template_retrieval(
    state: BoTState, config: RunnableConfig, store: BaseStore
) -> dict:
    """
    Retrieves the most relevant thought template for a given task using semantic search.

    This function conducts a semantic search between the distilled task and the task descriptions
    of thought templates stored in the long-term memory. It selects the template with the highest
    similarity score if it exceeds a user-defined threshold. If no suitable template is found, the 
    template field is left blank.

    Parameters
    ----------
    state : BoTState
        The current state of the agent, containing the distilled task and other relevant information.
    config : RunnableConfig
        Configuration object containing user-defined parameters, including the retrieval threshold.
    store : BaseStore
        The long-term memory store where thought templates are stored and queried.

    Returns
    -------
    dict
        A dictionary with the following key:
        - "template_text" : str or None
            The text of the retrieved thought template if it satisfies the similarity threshold, 
            otherwise None.
    """
    # Perform semantic search between the distilled task and templates in long-term memory
    items = store.search(namespace_for_memory,
                         query=state["distilled_task"], limit=1)
    template = items.pop() if items else None

    # Check if the retrieved template exceeds the similarity threshold
    if template and template.score > config["configurable"]["retrieval_threshold"]:
        template_text = json_to_markdown(
            {
                key: val
                for key, val in template.value.items()
                if key != "task_description"
            }
        )
        return {"template_text": template_text}
    else:
        return {"template_text": None}

# %% ../nbs/03_buffer_of_thought.ipynb 29
def instantiate_reasoning(state: BoTState) -> dict:
    """
    Executes the main solution step for the BoT agent by attempting to solve the problem.

    This function represents the core reasoning process in the Buffer of Thoughts (BoT) framework.
    It uses either a retrieved thought template to guide the solution or, if no template is available, 
    applies a general solution approach as defined in the prompt.

    Parameters
    ----------
    state : BoTState
        The current state of the agent, containing the task description, thought template (if retrieved), 
        and other relevant information.

    Returns
    -------
    dict
        A dictionary with the following key:
        - "messages" : str
            The result of the reasoning step, either guided by the thought template or generated 
            using a general approach.
    """
    if state["template_text"]:
        # Reasoning step guided by the retrieved thought template
        return {
            "messages": LLM.invoke(
                [
                    state["messages"][-1],
                    (
                        "user",
                        instantiate_reasoning_prompt
                        + f"\n\n<thought-template>\n{state['template_text']}\n<thought-template>",
                    ),
                ]
            )
        }
    else:
        # Reasoning step using a general solution approach
        return {
            "messages": LLM.invoke(
                [state["messages"][-1], ("user", instantiate_reasoning_prompt)]
            )
        }

# %% ../nbs/03_buffer_of_thought.ipynb 30
def template_distillation(state: BoTState, config: RunnableConfig, store: BaseStore) -> dict:
    """
    Distills a new thought template when no suitable template is found in the long-term memory.

    This function is used when the Buffer of Thoughts (BoT) agent fails to retrieve a proper thought 
    template. It distills a new template by analyzing the task description and the derived solution. 
    Relevant in-task and cross-task examples (i.e., similar and diverse thought templates) are retrieved 
    from the long-term memory to guide the derivation of a new template.

    Parameters
    ----------
    state : BoTState
        The current state of the agent, containing the distilled task, derived solution, and other relevant details.
    config : RunnableConfig
        Configuration object containing user-defined parameters, including thresholds and limits for in-task 
        and cross-task template retrieval.
    store : BaseStore
        The long-term memory store where thought templates are stored and queried.

    Returns
    -------
    dict
        A dictionary containing:
        - "messages" : str
            The distilled thought template generated by the BoT agent, guided by the retrieved in-task 
            and cross-task examples.
    """
    # Summarize the core task and solution steps
    core_task_summarization_msg = core_task_summarization_prompt.format(
        distilled_task=state["distilled_task"],
        solution_steps=state["messages"][-1].content,
    )
    # Generate task summary using LLM
    task_summary = LLM.invoke(core_task_summarization_msg)

    # Search for relevant thought templates in the long-term memory
    items = store.search(
        namespace_for_memory,
        query=task_summary.content,
        limit=config["configurable"]["limit"],
    )

    # Separate templates into in-task and cross-task examples based on their similarity scores
    in_task_l = [
        template
        for template in items
        if template.score > config["configurable"]["in_task_threshold"]
    ]
    in_task = in_task_l.pop(0) if in_task_l else None

    cross_task_l = [
        template
        for template in items
        if template.score <= config["configurable"]["in_task_threshold"]
    ]
    cross_task = cross_task_l.pop(0) if cross_task_l else None

    # Use in-task and cross-task examples to guide the generation of a new thought template
    return {
        "messages": LLM.invoke(
            [
                ("user", core_task_summarization_msg),  # Task summarization
                task_summary,  # Task summary message
                (
                    "user",
                    template_distiller_prompt.format(
                        task_summary=task_summary,
                        in_task_examples=json_to_markdown(
                            in_task.value if in_task else {}
                        ),
                        cross_task_examples=json_to_markdown(
                            cross_task.value if cross_task else {}
                        ),
                    ),
                ),
            ]
        )
    }

# %% ../nbs/03_buffer_of_thought.ipynb 31
def dynamic_meta_buffer_update(
    state: BoTState, config: RunnableConfig, store: BaseStore
) -> dict:
    """
    Structures the distilled template into predefined sections and stores it in the Long-Term Memory.

    This function processes the distilled template by organizing it into three sections: 
    'Task Description', 'Solution Description', and 'Thought Template', as defined by the Pydantic class. 
    The structured template is then stored in the Long-Term Memory in JSON format.

    Parameters
    ----------
    state : BoTState
        The current state of the agent, containing the distilled template and related data.
    config : RunnableConfig
        Configuration object with user-defined parameters and metadata for storing the structured template.
    store : BaseStore
        The long-term memory store where the structured template is saved in JSON format.

    Returns
    -------
    dict
        A dictionary containing:
        - "messages" : str
            A message confirming the successful update of the Meta Buffer.
    """
    # Structure the distilled template into defined sections using the structure prompt
    result = structure_template_text.invoke(
        {
            "messages": [
                structure_prompt.format(
                    conversation=state["messages"][-1].content
                )
            ]
        }
    )

    # Extract the structured response and associated metadata
    r, rmeta = result["responses"].pop(), result["response_metadata"].pop()

    # Store the structured template in the Long-Term Memory
    store.put(
        (user_id, long_term_memory),  # Memory namespace and user context
        rmeta.get("json_doc_id", str(uuid.uuid4())),  # Unique document ID
        r.model_dump(mode="json"),  # Save structured template as JSON
    )

    # Return confirmation of Meta Buffer update
    return {"messages": "Meta Buffer updated"}

# %% ../nbs/03_buffer_of_thought.ipynb 33
def update_required(state: BoTState) -> Literal["Buffer Manager", "END"]:
    if state["template_text"]:
        return "END"
    else:
        return "Buffer Manager"

# %% ../nbs/03_buffer_of_thought.ipynb 35
meta_buffer = StateGraph(BoTState)

# add nodes
meta_buffer.add_node("Template Retrieval", template_retrieval)
meta_buffer.add_node("Instantiated Reasoning", instantiate_reasoning)

# add edges
meta_buffer.add_edge(START, "Template Retrieval")
meta_buffer.add_edge("Template Retrieval", "Instantiated Reasoning")
meta_buffer.add_edge("Instantiated Reasoning", END)

# %% ../nbs/03_buffer_of_thought.ipynb 36
buffer_manager = StateGraph(BoTState)

# add nodes
buffer_manager.add_node("Template Distillation", template_distillation)
buffer_manager.add_node("Dynamic Update", dynamic_meta_buffer_update)

# add edges
buffer_manager.add_edge(START, "Template Distillation")
buffer_manager.add_edge("Template Distillation", "Dynamic Update")
buffer_manager.add_edge("Dynamic Update", END)

# %% ../nbs/03_buffer_of_thought.ipynb 37
memory = MemorySaver()
bot_graph = StateGraph(BoTState)

# add nodes
bot_graph.add_node("Problem Distiller", problem_distiller)
bot_graph.add_node("Meta Buffer", meta_buffer.compile(checkpointer=memory))
bot_graph.add_node(
    "Buffer Manager", buffer_manager.compile(checkpointer=memory))

# add edges
bot_graph.add_edge(START, "Problem Distiller")
bot_graph.add_edge("Problem Distiller", "Meta Buffer")
bot_graph.add_conditional_edges(
    "Meta Buffer", update_required, {
        "Buffer Manager": "Buffer Manager", "END": END}
)
bot_graph.add_edge("Buffer Manager", END)

# compile graph
bot_agent = bot_graph.compile(checkpointer=memory, store=template_store)
